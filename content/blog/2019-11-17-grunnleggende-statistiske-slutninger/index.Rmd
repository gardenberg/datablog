---
title: Grunnleggende statistiske slutninger fra utvalgsundersøkelser
author: Eivind
date: '2019-11-17'
slug: grunnleggende-statistiske-slutninger
categories:
  - R
  - statistikk
tags: []
---

__Hva handler denne artikkelen om?__ _Hvorfor gjennomføre en utvalgsundersøkelse, hvordan et utvalg fra en populasjon forholder seg til populasjonen, og hvordan du kan si noe om hvor sikker du er på at estimatet ditt fra utvalget er i nærheten av det reelle tallet_

En grunnleggende arbeidshest i en samfunnsviters verktøyboks er utvalgsundersøkelsen. En smarting fant på et tidspunkt ut at en ikke trengte å spørre alle i en populasjon et spørsmål, for å kunne si noe om hva hele populasjonen mente. 

I følge Ringdals "Enhet og mangfold" var dette en amerikansk nyvinning i mellomkrigstida som først slo igjennom etter andre verdenskrig (Ringdals bok er nå i sin fjerde utgave, ser jeg - selv er jeg den stolte eier av førsteutgaven, [anmeldt bl.a. her](https://www.ssb.no/befolkning/artikler-og-publikasjoner/bokanmeldelse-enhet-og-mangfold-av-kristen-ringdal)). Her går historien til utvalgsundersøkelser hånd i hånd med historien til holdningsundersøkelser, drevet fram av bl.a. George Gallupp. 

Rent umiddelbart er jeg litt skeptisk til denne framstillingen - for generaliseringer fra utvalg til populasjon må da ha vært vanlig også før dette? Om ikke i samfunnsvitenskapen, så på andre felt - som i [bryggeribransjen](https://en.wikipedia.org/wiki/Student%27s_t-test)? Nyvinningen var nok derfor heller at en brukte etablerte metoder fra andre områder, på samfunnsvitenskapelige sysler. 

Uansett, i dag er utvalgsundersøkelsen en riktig så sterk arbeidshest for en samfunnsviter. Riktignok ikke så sterk som før - med eksplosjonen i tilgjengelighet de siste årene har fallende svarprosenter blitt et problem for alle, over alt.

Rundt denne formen for undersøkelser finnes det en hel skole av slutningslogikk: **hvordan gjøre en slutning fra et utvalg, til en hel populasjon?**

1. vi lager noe eksempeldata for en hel populasjon
2. vi tar ett utvalg fra populasjonen, og ser om det treffer.
3. vi tar mange utvalg fra populasjonen, for å vise fram sannsynlighetsfordelinga til estimatet for gjennomsnittverdier.
4. ved hjelp av litt matte, beregner vi standardfeil for parameterestimatene fra utvalgene, som sier noe om usikkerheten vår.

Framstillingen bygger først og fremst på Skogs ["Å forklare sosiale fenomener"](https://www.gyldendal.no/Faglitteratur/Samfunnsfag/Statistikk-metode/AA-forklare-sosiale-fenomener), når jeg har trengt litt fasit-assistanse.

```{r, warning = FALSE, message = FALSE}
library(tidyverse)

#settings
theme_set(theme_minimal())
set.seed(1106)
options(scipen = 100)
```

## Populasjonens holdning til X!

Si at vi har en populasjon med 1000 enheter, som vi ønsker å vite noe om holdningene til på noen spørsmål:

- ett ja/nei-spørsmål (f.eks.: har du hest?)
- ett spørsmål hvor svaret kan oppgis som en kontinuerlig variabel (f.eks.: hva er hesten verdt?)
- ett holdningsspørsmål på en skala fra 1 til 5, fra svært dårlig via ok til svært god (f.eks.: hvor god er du til å ri på hest?).

Dessverre finner jeg ikke slike data liggende rundt, men jeg konstruerer de.

```{r}
df = data.frame("ID" = 1:1000, stringsAsFactors = FALSE)

#binomisk sannsynlighet for holdning #1 
df$holdning_1 = rbinom(1000, 1, 0.5)

#kontinuerlig normaltfordelt variabel på verdi holdning #2
df$holdning_2 = rnorm(1000, 12500, 2500)

#diskret sannsynlighet
#trekker denne fra en uniform fordeling, og runder av til nærmeste heltall
#kunne egentlig også brukt sample() med replacement = TRUE?
df$holdning_3 = round(runif(1000, min = 1, max = 5))

```

Fordelingen av holdningene i populasjonen ser da slik ut:

```{r, echo = FALSE}

ggplot(data = df) + 
  geom_bar(aes(x = as.factor(holdning_1))) + 
  labs(x = "Nei eller ja", y = "Antall", title = "Populasjonens faktiske holdning til #1", subtitle = "Har du hest == 1 ")

ggplot(data = df) + 
  geom_histogram(aes(x = holdning_2), binwidth = 1000) + 
  labs(x = "Verdianslag på hest", y = "Antall", title = "Populasjonens holdning til #2", subtitle = "Verdi av hest normalfordelt rundt 12 500")


ggplot(data = df) + 
  geom_bar(aes(x = holdning_3)) + 
  labs(x = "Holdning fra 1 til 5 til hest", y = "Antall", title = "Populasjonens faktiske holdning til #3", subtitle = "Fra 1 til 5 - hvor godt liker du hest?")

```

Her ser vi altså at 

- ja eller nei er temmelig likt fordelt i populasjonen (50,4 % sier ja)
- den kontinuerlige variabelen er normalfordelt rundt 12 500.
- 2, 3 og 4 er de mest populære svarene på #3, med minst på 5 og noe fler på 1.

Dette er ikke overraskende, men følger av hvordan variablene er konstruerte. Noe mer støy kunne nok vært lagt inn, for å gjøre det litt mer interessant.

Dette er holdninger eller verdier i populasjonen vår, bestående av 1000 enheter. Hva så når vi skal gjøre et utvalg?

## Utvalgets holdning til X

I de aller fleste tilfeller av slike holdningsundersøkelser kan vi imidlertid ikke undersøke hele populasjonens holdning til X. Det er for dyrt, for tidkrevende - og ofte også helt unødvendig. I stedet kan vi trekke et tilfeldig utvalg fra populasjonen. Dette går helt fint, gitt at:

- alle medlemmer har **samme sannsynlighet** for å komme med i utvalget, og
- sjansen for at en enhet kommer med, er **uavhengig** av om bestemte andre enheter kommer med

Så hvordan ville fordelinga av holdninga sett ut i et sjanseutvalg på f.eks. 100 personer?

```{r}
utvalg = sample_n(df, 100, replace = FALSE)
```

Antallet er åpenbart annerledes - men treffer utvalget på samme andeler?

```{r, echo = FALSE}
temp_1 = group_by(df, holdning_1) %>%
  summarise(., antall = n()) %>%
  mutate(andel = antall/sum(antall))

temp_2 = group_by(utvalg, holdning_1) %>%
  summarise(., antall = n()) %>%
  mutate(andel = antall/sum(antall))

temp = bind_rows(populasjon = temp_1, utvalg = temp_2, .id = "data")

#holdning_1
ggplot(data = temp) +
  geom_col(aes(x = holdning_1, y = andel, fill = data), position = "dodge") + 
  labs(title = "Sammenlikning av utvalg og populasjon på binomisk fordelt variabel")

#holdning_2
ggplot() +
  geom_freqpoly(aes(x = holdning_2, y = stat(density)), colour = "red", data = df, binwidth = 1000) + 
  geom_freqpoly(aes(x = holdning_2, y = stat(density)), colour = "blue", data = utvalg, binwidth = 1000) +
  labs(title = "Sammenlikning av utvalg og populasjon på normalfordelt variabel")

#holdning_3
temp_1 = group_by(df, holdning_3) %>%
  summarise(., antall = n()) %>%
  mutate(andel = antall/sum(antall))

temp_2 = group_by(utvalg, holdning_3) %>%
  summarise(., antall = n()) %>%
  mutate(andel = antall/sum(antall))

temp = bind_rows(populasjon = temp_1, utvalg = temp_2, .id = "data")

#holdning_1
ggplot(data = temp) +
  geom_col(aes(x = holdning_3, y = andel, fill = data), position = "dodge") + 
  labs(title = "Sammenlikning av utvalg og populasjon på diskret variabel")


```

Naturlig nok - ikke helt. Men hvor nærme er dette? Og hvor nærme kunne vi sagt at det var, hvis vi ikke hadde kjent de rød verdiene - populasjonsverdiene? 

For å svare på det, må vi en liten omtur om sannsynlighetsfordelinger:

## Sannsynlighetsfordeling av gjennomsnittsverdier
Vi har nå en populasjon, og et utvalg fra denne populasjonen som ikke treffer helt på den sanne virkeligheten. Vanligvis kjenner du ikke populasjonens sanne fordeling, eller hvilke egenskaper den har. Så hvordan kan du gjøre slutninger basert på utvalget? Jo, via en teoretiske sannsynlighetsfordeling for egenskaper ved det du måler. Se for det at du trekker mange utvalg fra samme populasjon - hvordan ville denne fordelt seg?

Hvis vi trekker noen utvalg fra populasjonen vår, kan vi visualisere dette:

```{r}
utvalg = sample_n(df, 100, replace = FALSE)
utvalg$utvalgsnummer = 1

for(i in 2:100){
  temp = sample_n(df, 100, replace = TRUE)
  temp$utvalgsnummer = i
  utvalg = bind_rows(utvalg, temp)
}
```

Vi kan begynne med det første spørsmålet - ja eller nei-spørsmålet, kodet som 0 og 1. Hvis vi beregner gjennomsnittlig andel som har besvart dette med ja i de ulike utvalgene, så kan vi vise hvordan gjennomsnittene i disse utvalgene fordeler seg.

```{r, echo = FALSE, warning = FALSE}
#holdning_1
temp = select(utvalg, ID, holdning_1, utvalgsnummer) %>%
  group_by(utvalgsnummer) %>%
  summarise(gjennomsnitt = mean(holdning_1))

ggplot() + 
  geom_freqpoly(aes(x = gjennomsnitt, y = stat(density)), binwidth = 0.05, colour = "red", data = filter(temp, utvalgsnummer < 10)) + 
    geom_freqpoly(aes(x = gjennomsnitt, y = stat(density)), binwidth = 0.05, colour = "blue", data = filter(temp, utvalgsnummer < 20)) + 
    geom_freqpoly(aes(x = gjennomsnitt, y = stat(density)), binwidth = 0.05, colour = "green", data = filter(temp, utvalgsnummer < 50)) + 
    geom_freqpoly(aes(x = gjennomsnitt, y = stat(density)), binwidth = 0.05, colour = "black", data = temp) + 
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1), minor_breaks = NULL, limits = c(0,1))

```

Den svarte linja viser fordelinga av gjennomsnittlig andel hesteeiere i 100 utvalg fra populasjonen. Den røde, blå og grønne viser henholdsvis 10, 20 og 50 utvalgsgjennomsnitt. Jo flere utvalg, jo mer bør den sentrere seg rundt der vi - fra over - veit at det faktiske gjennomsnittet ligger.

Tilsvarende øvelse kan gjentas for den kontinuerlige variabelen, og den diskrete variabelen.

```{r, echo = FALSE, warning = FALSE}
#holdning_2
temp = select(utvalg, ID, holdning_2, utvalgsnummer) %>%
  group_by(utvalgsnummer) %>%
  summarise(gjennomsnitt = mean(holdning_2))

ggplot() + 
  geom_freqpoly(aes(x = gjennomsnitt, y = stat(density)), binwidth = 250, colour = "red", data = filter(temp, utvalgsnummer < 10)) + 
    geom_freqpoly(aes(x = gjennomsnitt, y = stat(density)), binwidth = 250, colour = "blue", data = filter(temp, utvalgsnummer < 20)) + 
    geom_freqpoly(aes(x = gjennomsnitt, y = stat(density)), binwidth = 250, colour = "green", data = filter(temp, utvalgsnummer < 50)) + 
    geom_freqpoly(aes(x = gjennomsnitt, y = stat(density)), binwidth = 250, colour = "black", data = temp) + 
  scale_x_continuous(breaks = seq(from = 11000, to = 14000, by = 500), minor_breaks = NULL, limits = c(11000, 14000))

#holdning_3
temp = select(utvalg, ID, holdning_3, utvalgsnummer) %>%
  group_by(utvalgsnummer) %>%
  summarise(gjennomsnitt = mean(holdning_3))

ggplot() + 
  geom_freqpoly(aes(x = gjennomsnitt, y = stat(density)), binwidth = 0.1, colour = "red", data = filter(temp, utvalgsnummer < 10)) + 
    geom_freqpoly(aes(x = gjennomsnitt, y = stat(density)), binwidth = 0.1, colour = "blue", data = filter(temp, utvalgsnummer < 20)) + 
    geom_freqpoly(aes(x = gjennomsnitt, y = stat(density)), binwidth = 0.1, colour = "green", data = filter(temp, utvalgsnummer < 50)) + 
    geom_freqpoly(aes(x = gjennomsnitt, y = stat(density)), binwidth = 0.1, colour = "black", data = temp) + 
  scale_x_continuous(breaks = seq(from = 2.5, to = 3.5, by = 0.5), minor_breaks = NULL, limits = c(2,4))
```

Så hva er poenget med dette? Deto flere utvalg en trekker fra en populasjon, jo flere av utvalgene vil ha gjennomsnitt i nærheten av det sanne utvalget. Dette gjelder særlig for større utvalg (over ca. 50?). For de fleste praktiske formål, hvor vi ikke kjenner populasjonsverdien, og vi ikke kan måle den direkte, er det også upraktisk å ta et stort antall utvalgsundersøkelser. Men fordi vi ser at parameterestimatene i et stort antall utvalg er om lag normalfordelt (også for verdier som ikke selv er normalfordelte), kan vi estimere hvor usikre vi er på at den sanne populasjonen ligger innafor et intervall rundt punktestimatet vårt. 

## Slutninger om en andel 

Den unøyaktigheten vi får når vi bruker andelen fra et utvalg som estimat for andelen i en populasjon, kan måles med standardfeilen til estimatet. En vanlig tommelfingerregel for unøyaktighetsberegninger er ca. to ganger standardfeilen på hver side av parameterestimatet.

```{r}
utvalg = filter(utvalg, utvalgsnummer == 1)

# Når populasjonsandelen er kjent

#standardfeil for et estimat til en andel
p = sum(df$holdning_1/length(df$holdning_1)) #faktisk andel i populasjonen
sem = sqrt(p*(1-p))/sqrt(length(utvalg$ID))

temp = data.frame("populasjonsparameter_kjent" = FALSE, "andel" = p, "standardfeil" = sem)

# Når populasjonsandelen er ukjent

#standardfeil for et estimat til en andel
p_hat = sum(utvalg$holdning_1/length(utvalg$holdning_1)) #parameterestimatet fra utvalget
sem = sqrt(p_hat*(1-p_hat))/sqrt(length(utvalg$ID))

temp = bind_rows(temp, data.frame("populasjonsparameter_kjent" = FALSE, "andel" = p_hat, "standardfeil" = sem))
```


```{r}
knitr::kable(temp)
```


I mitt eksempel (som bør være det samme som eksempelet som vises her, siden jeg har brukt set.seed()) er andelen som har svart ja på holdningsspørsmål 1 54,4 % i populasjonen på 1000 personer. Som vi ser av formelen, avgjøres sikkerheten av størrelsen på utvalget og størrelsen på andelen i populasjonen: Jo nærmere den faktiske andelen er 50 %, jo større usikkerhet. Og jo større utvalg, destor mindre usikkerhet. I vårt tilfelle er andelen ganske nær 50 %, og utvalget er på 100 personer. Standardfeilen er derfor på ca. 5 %, eller mellom 44 % og 64 %

I utvalget vi har tatt, har 53 % svart ja. Standardfeilen er veldig lik her, som i eksempelet over - faktisk kan en vel si helt lik, når de 8 første desimalene er like. Dvs. at standardfeilen tilsier at den sanne verdien ligger et sted mellom 43 % og 63 %. 

## Kontinuerlig variabel

```{r}

#når gjennomsnittet i populasjonen er kjent

#standardfeil for estimatet til gjennomsnittet av en kontinuerlig, normalfordelt variabel
s = mean(df$holdning_2) #gjennomsnitt i populasjonen
sem = s/sqrt(length(utvalg$ID))

temp = data.frame("populasjonsparameter_kjent" = TRUE, "gjennomsnitt" = s, "standardfeil" = sem)

#når gjennomsnittet i populasjonen er ukjent

s_hatt = mean(utvalg$holdning_2) #parameterestimatet for gjennomsnitt
sem = s_hatt/sqrt(length(utvalg$ID))

temp = bind_rows(temp, data.frame("populasjonsparameter_kjent" = FALSE, "gjennomsnitt" = s_hatt, "standardfeil" = sem))
```


```{r}
knitr::kable(temp)
```



Her er gjennomsnittsverdien i populasjonen 12 393 (kroner for en hest). Den beregnede standardfeilen for utvalg er 1 239, dvs. at ca. 95 % av utvalg vil være mellom 9 915 og 14 871. 

For utvalget ser vi at gjennomsnittet er på 12 575 (kroner for en hest). Dette er ikke langt unna den sanne verdien - men det er helt tilfeldig. Et konfidensintervall rundt dette punktestimatet vil være fra 10 061 til 15 089. Dvs. et ganske stort sprang fra rundt 10 til 15 000 kroner. 

## Kategorisk variabel

En tilsvarende tilnærming som denne kan brukes for vårt holdningsspørsmål nr. 3. Her kunne vi både anslått standardfeil for andelsestimater ("hvor stor andel liker ikke hest?"), og for gjennomsnittsestimtatet ("hva er den gjennomsnittlige holdninga til hest?"). Matematikken følger samme mønster som over.